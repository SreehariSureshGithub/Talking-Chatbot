{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.corpus import wordnet\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize pyttsx3 engine\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[1].id)\n",
    "\n",
    "# Load the trained model and data\n",
    "model = load_model('chatbot_model.h5')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "spell = SpellChecker()\n",
    "\n",
    "with open(\"intents.json\") as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "# Prepare the words and classes\n",
    "words = sorted(set([lemmatizer.lemmatize(w.lower()) for intent in intents['intents'] for pattern in intent['patterns'] for w in nltk.word_tokenize(pattern) if w not in ['?', '!', '.', ',']]))\n",
    "classes = sorted(set(intent['tag'] for intent in intents['intents']))\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "def expand_with_synonyms(words):\n",
    "    expanded_words = set(words)\n",
    "    for word in words:\n",
    "        synonyms = get_synonyms(word)\n",
    "        expanded_words.update(synonyms)\n",
    "    return list(expanded_words)\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    # Tokenize and lemmatize\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    \n",
    "    # Expand with synonyms\n",
    "    sentence_words = expand_with_synonyms(sentence_words)\n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words, show_details=True):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print(f\"Found in bag: {w}\")\n",
    "    return np.array(bag)\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    p = bow(sentence, words, show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "def get_response(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if i['tag'] == tag:\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def chatbot_response(text):\n",
    "    ints = predict_class(text, model)\n",
    "    res = get_response(ints, intents)\n",
    "    return res\n",
    "\n",
    "def text_to_speech(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def send(event=None):\n",
    "    msg = entry_box.get(\"1.0\",'end-1c').strip()\n",
    "    entry_box.delete(\"0.0\", tk.END)\n",
    "\n",
    "    if msg != '':\n",
    "        chat_log.config(state=tk.NORMAL)\n",
    "        chat_log.insert(tk.END, \"You: \" + msg + '\\n\\n')\n",
    "        chat_log.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
    "        \n",
    "        res = chatbot_response(msg)\n",
    "        chat_log.insert(tk.END, \"Bot: \" + res + '\\n\\n')\n",
    "        \n",
    "        # Speak the response\n",
    "        text_to_speech(res)\n",
    "            \n",
    "        chat_log.config(state=tk.DISABLED)\n",
    "        chat_log.yview(tk.END)\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Chatbot\")\n",
    "root.geometry(\"400x500\")\n",
    "root.resizable(width=False, height=False)\n",
    "\n",
    "# Create chat window with integrated scrollbar\n",
    "chat_log = scrolledtext.ScrolledText(root, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\")\n",
    "chat_log.config(state=tk.DISABLED)\n",
    "\n",
    "# Create the button to send message\n",
    "send_button = tk.Button(root, font=(\"Verdana\", 12, 'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                        bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\", fg='#ffffff',\n",
    "                        command=send)\n",
    "\n",
    "# Create the box to enter message\n",
    "entry_box = tk.Text(root, bd=0, bg=\"white\", width=\"29\", height=\"5\", font=\"Arial\")\n",
    "\n",
    "# Bind the Enter key to the send function\n",
    "entry_box.bind(\"<Return>\", send)\n",
    "\n",
    "# Place all components on the screen\n",
    "chat_log.place(x=6, y=6, height=386, width=388)\n",
    "entry_box.place(x=6, y=401, height=90, width=265)\n",
    "send_button.place(x=275, y=401, height=90)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
